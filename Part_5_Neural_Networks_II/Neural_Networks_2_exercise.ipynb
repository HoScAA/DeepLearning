{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks II - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb DataSet - Binary Classification\n",
    "\n",
    "In dieser Übung betrachten wir das IMDb (Internet Movie Database) Dataset. Dieses enthält\n",
    "50.000 Movie Reviews, die hälftig postiv (y=1) bzw. negativ (y=0) ausfallen (siehe auch https://keras.io/datasets/ $\\rightarrow$ IMDB Movie reviews sentiment classification).\n",
    "\n",
    "- Lesen Sie die Daten ein, wobei Sie nur 1000 meist verwendeten Worte für jeden Review verwenden (option num_words). Die Daten sind in diesem Fall Python-Listen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lesen Sie die Dictionary word_index ein, welches  \n",
    "$$\n",
    "\\mathrm{word}\\quad \\rightarrow \\quad \\mathrm{integer\\,index}\n",
    "$$\n",
    "zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Erstellen Sie daraus ein Dictionary reverse_word_index, welches \n",
    "$$\n",
    "\\mathrm{integer\\,index}\\quad \\rightarrow \\quad \\mathrm{word}\n",
    "$$\n",
    "zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(val,key) for (key,val) in word_index.items() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lesen Sie damit zur Illustration einen beliebigen Review aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index.get(2,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful and and their becomes and had and of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every and and movie except her was several of enough more with is now and film as you of and and unfortunately of you than him that with out themselves her get for was and of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of and and with heart had and they of here that with her serious to have does when from why what have and they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br and to whether from than out themselves history he name half some br of and and was two most of mean for 1 any an and she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her and most that with wasn't to with and acting watch an for with and film want an\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a movie review\n",
    "' '.join([reverse_word_index.get(i,'') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Führen Sie ein One-Hot-Encoding der Training- und Testdaten durch. Erstellen Sie dazu\n",
    "jeweils eine $m\\times n$-Matrix, welche in jeder Zeile (=für jeden Review) jeweils eine 1 an der Index-Stelle enthält, an der ein Wort in dem entsprechenden Review vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def one_hot_encode(data,n=1000):\n",
    "    results = np.zeros((len(data),1000))\n",
    "    for i,rev in enumerate(data): \n",
    "        results[i,rev] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = one_hot_encode(train_data)\n",
    "X_test  = one_hot_encode(test_data)\n",
    "y_train = np.asarray(train_labels)\n",
    "y_test = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitten Sie vom Testset die ersten 10.000 Daten ab für die Validierung während des Trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_test[:10000,:]\n",
    "y_val = y_test[:10000]\n",
    "X_test = X_test[10000:,:]\n",
    "y_test = y_test[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Erstellen Sie ein neuronales Netz mit zwei Zwischenschichten der Größe $h_1=h_2=16$ und verwenden Sie beim Ausgang die Aktivierung sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilieren Sie das Model mit den Optionen \n",
    "    -  loss='binary_crossentropy'\n",
    "    -  metrics=['accuracy']\n",
    "    \n",
    "und trainieren Sie anschliessend Ihr Model mit den oben festgelegten Traings- und Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotten Sie die Accuracy von Training und Test Set über die Epochen und berechnen Sie die accuracy bezüglich des Test-Sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST-Fashion Data Set (Multiclass Classification)\n",
    "\n",
    "Das MNIST-Fashion DataSet enthält 70.000 Bilder (60.000 Training, 10.000 Test) mit den 10 Kategorien:\n",
    "\n",
    "| Index | Item  |\n",
    "|---|-------------|\n",
    "|0\t| T-shirt/top |\n",
    "|1\t| Trouser     |\n",
    "|2\t| Pullover    |\n",
    "|3\t|Dress        |\n",
    "|4  |Coat         |\n",
    "|5\t|Sandal       |\n",
    "|6\t|Shirt        |\n",
    "|7\t|Sneaker      |\n",
    "|8\t|Bag          |\n",
    "|9\t|Ankle boot   |\n",
    "\n",
    "- Lesen Sie Trainings- und Testdatein ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zeigen Sie ein beliebiges Bild an (mittels imshow https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Führen Sie analog zur Vorlesung ein Preprocessing der Daten durch, in dem Sie\n",
    "    - Für Trainings- und Testdaten die letzten beiden Dimensionen (der Größe $28\\times 28$) das Datentensors auf\n",
    "    eine Dimension (der Größe $28^2$) kontrahieren\n",
    "    - Die Pixelwerte von $[0,255]$ auf das Intervall $[0,1]$ abbilden\n",
    "    - Von den Trainingsdaten die ersten 5.000 für die Validierung absplitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie dann folgende Schritte aus\n",
    "\n",
    "- Erstellen Sie ein geeignetes Neuronales Netz für diese Multiclass Classification\n",
    "- Compilieren und trainieren Sie ihr Netz\n",
    "- Plotten Sie die Accuracy des Training- und Validierungssets über die Epochen\n",
    "- Berechnen Sie die Accuracy bezüglich des Testsets\n",
    "- Lassen Sie die Confusion-Matrix für das Testset ausgeben (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Data Set (Regression)\n",
    "Das Boston Housing Data Set gibt die Preise von Häusern in Boston als Funktion der 13 Features, die in der\n",
    "folgenden Tabelle gezeigt sind an.\n",
    "\n",
    "|feature | label | content|\n",
    "|--|--|--|\n",
    "|0  |CRI     |     per capita crime rate by town     |\n",
    "|1  |ZN      |    proportion of residential land zoned for lots over 25,000 sq.ft.|\n",
    "|2  |INDUS   |    proportion of non-retail business acres per town|\n",
    "|3  |CHAS    |    Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)|\n",
    "|4  |NOX     |    nitric oxides concentration (parts per 10 million)|\n",
    "|5  |RM      |    average number of rooms per dwelling|\n",
    "|6  |AGE     |    proportion of owner-occupied units built prior to 1940|\n",
    "|7  |DIS     |    weighted distances to five Boston employment centres|\n",
    "|8  |RAD     |    index of accessibility to radial highways|\n",
    "|9  |TAX     |    full-value property-tax rate per \\$10,000|\n",
    "|10 |PTRATIO |  pupil-teacher ratio by town|\n",
    "|11 |B       | $1000(B_k - 0.63)^2$ where $B_k$ is the proportion of blacks by town|\n",
    "|12 |MEDV    | Median value of owner-occupied homes in \\$1000's|\n",
    "\n",
    "- Lesen Sie die Daten ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bereinigen Sie Ihre Daten vom Mittelwert und skalieren Sie auf eine Varianz von 1. Berechnen dazu den den Mittelwert $\\vec{\\mu}$ und die Standardabweichung $\\vec{\\sigma}$ des Training Sets (für alle features über alles Trainingsbeispiele). Ziehen dann $\\mu$ von Training und Test Set ab und teilen Sie anschliessend durch $\\vec{\\sigma}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train -= mean\n",
    "X_train /=std\n",
    "\n",
    "X_test -= mean\n",
    "X_test /=std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generieren Sie ein neuronales Netz mit zwei Hiddenlayern der Größe $h_1=h_2=64$. Der Ausgabelayer erhält hier\n",
    "keine Aktivierung, das es sich um eine Regression handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kompilieren Sie das Model mit loss='mse' (\"Mean-Squared-Error\") und  metrics=['mae'] (\"Mean-Absolute-Error\") und führen Sie anschliessend das Training\n",
    "mit allen Trainingsdaten über 80 Epochen mit einem batch_size von 16 durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Your code here\n",
    "################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluieren Sie den mae (\"Mean-Absolute-Error\") für das Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Your code here\n",
    "################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
