{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_MODELS_URL = \"http://download.tensorflow.org/models\"\n",
    "INCEPTION_V3_URL = TF_MODELS_URL + \"/inception_v3_2016_08_28.tar.gz\"\n",
    "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
    "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
    "\n",
    "def download_progress(count, block_size, total_size):\n",
    "    percent = count * block_size * 100 // total_size\n",
    "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n",
    "    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n",
    "        return\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    tgz_path = os.path.join(path, \"inception_v3.tgz\")\n",
    "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
    "    inception_tgz = tarfile.open(tgz_path)\n",
    "    inception_tgz.extractall(path=path)\n",
    "    inception_tgz.close()\n",
    "    os.remove(tgz_path)\n",
    "fetch_pretrained_inception_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "CLASS_NAME_REGEX = re.compile(r\"^n\\d+\\s+(.*)\\s*$\", re.M | re.U)\n",
    "\n",
    "def load_class_names():\n",
    "    with open(os.path.join(\"datasets\", \"inception\", \"imagenet_class_names.txt\"), \"rb\") as f:\n",
    "        content = f.read().decode(\"utf-8\")\n",
    "        return CLASS_NAME_REGEX.findall(content)\n",
    "class_names =  [\"background\"] + load_class_names()\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 299, 299, 3], name=\"X\")\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(\n",
    "        X, num_classes=1001, is_training=False)\n",
    "predictions = end_points[\"Predictions\"]\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from datasets/inception/inception_v3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame,(299,299))\n",
    "    \n",
    "        X_im = 2*(1.0/255.0*frame)-1\n",
    "        X_image = X_im.reshape(-1, 299, 299, 3)\n",
    "        predictions_val = predictions.eval(feed_dict={X: X_image})\n",
    "        most_likely_class_index = np.argmax(predictions_val[0])\n",
    "        most_likely_class_index\n",
    "        # Our operations on the frame come here\n",
    "        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow(class_names[most_likely_class_index],X_im)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
